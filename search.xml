<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[项目实训-利用XGboost进行新楼盘价格预测]]></title>
    <url>%2F2019%2F03%2F23%2Fxgboost%2F</url>
    <content type="text"><![CDATA[前言本来这个需求不在列表中，受到Kaggle比赛：Kaggle Boston Housing(https://www.kaggle.com/c/boston-housing)的启发，加入了这个功能。因为数据全部靠自己收集，特征也远不如比赛中的数据集多，最终预测的效果我觉得虽然误差比较大，但是也有一定的参考价值。 数据清洗和特征工程从数据库中抽取了一部分好量化的上海市数据作为基本信息，在此基础之上，引入了该楼盘周边1km范围内地铁站数量、医院数量、学校数量、商场数量（数据来自百度API，可以参见另一篇blog）和该楼盘所在区域的区域均价。从Figure1中可以看到从某壳网上爬取下来的数据中包含很多汉字、符号，还有缺失值需要填补，另外还有格式不统一的情况，所以在数据清洗上花了很多时间。对数据中的字符型数据转换：12345678# 数据预处理，填充缺失值以及特征中含有字符的转换为数值型# "price","propertyType","landscapingRatio","siteArea","floorAreaRatio","buildingArea","yearofpropertyRights",# "numPlan","parkingRatio","propertycosts","parkingSpace","hospital","metro","school","mall","id"# 住宅：1 写字楼：2 别墅：3 商业：4train.loc[train["propertyType"] == "住宅", "propertyType"] = 1train.loc[train["propertyType"] == "写字楼", "propertyType"] = 2train.loc[train["propertyType"] == "别墅", "propertyType"] = 3train.loc[train["propertyType"] == "商业", "propertyType"] = 4 对部分特征统一数据格式后，缺失值用均值进行填补：123456789101112131415train['landscapingRatio'] = train['landscapingRatio'].fillna(train.groupby('propertyType')['landscapingRatio'].transform('mean'))train['siteArea'] = train['siteArea'].fillna(train.groupby('propertyType')['siteArea'].transform('mean'))train['floorAreaRatio'] = train['floorAreaRatio'].fillna(train.groupby('propertyType')['floorAreaRatio'].transform('mean'))train['buildingArea'] = train['buildingArea'].fillna(train.groupby('propertyType')['buildingArea'].transform('mean'))train = train.fillna(0)train['yearofpropertyRights'] = train['yearofpropertyRights'].astype(float)train['numPlan'] = train['numPlan'].astype(int)train['parkingRatio'] = train['parkingRatio'].astype(float)train['propertycosts'] = train['propertycosts'].astype(float)train['parkingSpace'] = train['parkingSpace'].astype(int)train['yearofpropertyRights'] = train['yearofpropertyRights'].fillna(train.groupby('propertyType')['yearofpropertyRights'].transform('mean'))train['numPlan'] = train['numPlan'].fillna(train.groupby('propertyType')['numPlan'].transform('mean'))train['parkingRatio'] = train['parkingRatio'].fillna(train.groupby('propertyType')['parkingRatio'].transform('mean'))train['propertycosts'] = train['propertycosts'].fillna(train.groupby('propertyType')['propertycosts'].transform('mean'))train['parkingSpace'] = train['parkingSpace'].fillna(train.groupby('propertyType')['parkingSpace'].transform('mean')) XGboost简介建模预测结果]]></content>
      <tags>
        <tag>Python</tag>
        <tag>项目实训</tag>
        <tag>XGboost</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目实训-第二周总结]]></title>
    <url>%2F2019%2F03%2F11%2Fweek2%2F</url>
    <content type="text"><![CDATA[前言第二周结束项目的大部分简单需求已经实现，超过了预期的速度。两个组员在隔壁新国大实习，我周五也要去Bosch实习了，下周要加快进度。 定位网站的定位是面向购买新房的投资者或者有住房提升需求的买房者的功能性网站，数据分析＞房源展示。 已完成的需求 按用户输入城市名称，爬取和显示城市不同小区，不同区域的房价，并用柱状图显示看了周一的模拟产品发布以后，发现隔壁组的UI做的很好看，扁平化设计，准备在产品功能实现后再调整。 按年份，月份，显示和分析某区域房价走向和趋势收集到的数据的粒度到月，住建局有到天的成交数据，但是很多特征都没有就没有采集。ECharts确实很好用，提供了一些直观、易用的交互方式以方便对所展现数据的再加工。待完成的需求预测模型的训练已经完成，为了不和其他组撞车，准备加入两个预测模块。1.新楼盘开盘价预测（博文会在第三周整理后发布）输入：用户输入新楼盘的一些信息，城市+小区名称（在后台调用百度地图API返回小区周边信息数据）、绿化率、容积率、车位比等数据输出：该新楼盘的开盘价格(基于XgBoost)图中的蓝色点是训练集中上海新楼盘的真实信息，但是训练的结果和Kaggle中波士顿房价预测那题的结果相差甚远，我想有几个原因：第一是上海主城区房价过高，但是新楼盘少，新城区房价较低，新楼盘多，这些离群点让模型产生了较大误差；第二，Kaggle比赛的数据集很全，虽然说有缺失值和部分错误值，但是用Pandas完全可以解决这些小错误，我们这次预测的数据集60%来自链家，40%是自己收集的，在专业性上相差较多，导致没有比赛数据集所呈现的统计规律。2.房价走势预测（博文会在第三周整理后发布）输入：数据库中某城市粒度位月的历史房价输出：未来一个月的房价趋势（基于LSTM）]]></content>
      <categories>
        <category>项目实训</category>
      </categories>
      <tags>
        <tag>项目实训</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas处理数据时replace方法失效]]></title>
    <url>%2F2019%2F03%2F05%2Fweek123%2F</url>
    <content type="text"><![CDATA[BUG复现1train.replace('%', '', inplace=True) 使用replace函数的目的是：在清洗房价数据时替换掉不需要的单位，如“%”，“元/m²/月”等。但在使用函数时发现无法生效，查了网上相关信息后试了多种方法也无法解决这个问题，如先取列之后再进行replace。1train["landscapingRatio"].replace('%', '', inplace=True) 原因推测dataframe中每个列中值的dtypes不同，导致无法replace。 解决方法使用map()和lambda函数1train["landscapingRatio"] = train["landscapingRatio"].map(lambda x: x.replace('%', '')) map() 会根据提供的函数对指定序列做映射。第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。]]></content>
      <categories>
        <category>项目实训</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>房价预测</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目实训第一周总结]]></title>
    <url>%2F2019%2F03%2F03%2Fhousepricingweek1%2F</url>
    <content type="text"><![CDATA[前言寒假前已经定好了这次项目实训的题目，放假的时候群里关于房价数据爬虫的讨论随着一句“过完年再说”戛然而止，然而第一周已经结束了才空出时间来写总结。 项目需求城市房价分析系统技术类别：Web，网络爬虫，数据分析基本功能：通过爬取链家网，我爱我家等中介机构，以及城市建设局网站数据，实现对指定城市的房价进行排序和分析，并结合一定规律进行预测难易程度：中等需求实现： 按用户输入城市名称，爬取和显示城市不同小区，不同区域的房价，并用柱状图显示 按年份，月份，显示和分析某区域房价走向和趋势 对比相同价格下不同城市的房产品牌 对比不同城市房价走向，并进行归类分析 实现房价波动的简单预测 需求理解1.项目是什么？一个Web，可以向用户展示粒度从市—行政区—具体楼盘的统计数据，可以根据用户提供的新楼盘数据做预测。2.项目怎么做？Java Web(Spring bot, vue.js, Echarts)Python(bs4, sklearn, pandas等)MySQL百度API（POI相关信息获取）预测模型XgBoost + LR/DT, 是否采用Deep Learning视项目进度决定 开发模式Scrum敏捷开发模式，lm担任产品经理，ltz担任技术主管，我是master。作为master在项目中要负责管理上的事务很多，经理日报，进度控制，每日组会，团建等等，对人际沟通能力是个很好的提升。组员都很自觉，分工我和lm负责数据和预测部分，另外三位负责Web。 第一周进度 数据部分：爬虫完成，爬取了某壳网上一线城市和二线城市的数据 Web部分：通过百度地图的控件可以在地图上显示城市和行政区的统计数据，校对经纬度花了挺久。 预测部分：数据清洗中，第二周预测模块应该能实现。]]></content>
      <categories>
        <category>项目实训</category>
      </categories>
      <tags>
        <tag>房价预测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度地图API解析]]></title>
    <url>%2F2019%2F02%2F28%2FbaiduAPI%2F</url>
    <content type="text"><![CDATA[功能简介百度地图Web服务API为开发者提供http/https接口，即开发者通过http/https形式发起检索请求，获取返回json或xml格式的检索数据。用户可以基于此开发JavaScript、C#、C++、Java等语言的地图应用。http://lbsyun.baidu.com/index.php?title=webapi文档非常全面，可以获得很多信息，包括经纬度，经纬度周边任意距离任意类型场所信息，如医院、地铁站等，为预测做准备。以正/逆地理编码服务为例。 Python如何解析API返回的json所用到的库12import jsonfrom urllib.request import urlopen, quote 获得API传回的json信息1showLocation&amp;&amp;showLocation(&#123;"status":0,"result":&#123;"location":&#123;"lng":120.75204667293927,"lat":31.27628928466111&#125;,"precise":1,"confidence":80,"comprehension":100,"level":"道路"&#125;&#125;) 1234567891011def getlnglat(address): url = 'http://api.map.baidu.com/geocoder/v2/' output = 'json' ak = '你的密钥' add = quote(address) # 由于本文城市变量为中文，为防止乱码，先用quote进行编码 uri = url + '?' + 'address=' + add + '&amp;output=' + output + '&amp;ak=' + ak print(uri) req = urlopen(uri) res = req.read().decode() # 将其他编码的字符串解码成unicode responseInfo = json.loads(res) # 对json数据进行解析 return responseInfo 取得所需的信息123add = "江苏省苏州市苏州工业园区林泉街399号东南大学软件学院" # 你所要查询的地址lat = getlnglat(add)['result']['location']['lat'] # 获得纬度lng = getlnglat(add)['result']['location']['lng'] # 获得经度 结果lat = 31.27628928466111lng = 120.75204667293927]]></content>
      <categories>
        <category>项目实训</category>
      </categories>
      <tags>
        <tag>百度</tag>
        <tag>API</tag>
        <tag>json</tag>
        <tag>Python</tag>
        <tag>房价预测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯估计与最大似然估计]]></title>
    <url>%2F2018%2F12%2F02%2F%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1%E4%B8%8E%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[贝叶斯估计：估计参数$\theta$是随机变量，根据观测数据对参数的分布进行估计，考虑先验分布。 最大似然估计：参数$\theta$是未知的，根据真实数据通过最大化似然函数$\mathop{\arg\max}_{\theta}L(\theta|D)$来估计$\theta$的值 最大似然估计 贝叶斯估计 计算复杂度 微分 多重积分 先验信息的信任程度 不准确 准确 例如$p(x丨\theta)$ 与初始假设一致 与初始假设不一致]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>贝叶斯</tag>
        <tag>最大似然估计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论4.5-主方法]]></title>
    <url>%2F2018%2F11%2F12%2F%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA4-5-%E4%B8%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[算法导论练习4.5-1对下列递归式，使用主方法求出渐进紧缺界: $T(n) = 2T(n/4) + 1$$T(n) = 2T(n/4) + \sqrt{n}$$T(n) = 2T(n/4) + n$$T(n) = 2T(n/4) + n^2$Answer： $\Theta(n^{\log_4{2}}) = \Theta(\sqrt{n})$$\Theta(n^{\log_4{2}}\lg{n}) = \Theta(\sqrt{n}\lg{n})$$\Theta(n)$$\Theta(n^2)$]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习实战》SVM补充内容]]></title>
    <url>%2F2018%2F10%2F21%2F%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E3%80%8BSVM%E8%A1%A5%E5%85%85%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[对于《机器学习实战》一书SVM章节程序清单6-2 简化版SVM算法中部分代码的数学原理补充 if(labelMat[i] != labelMat[j]): L = max(0, alphas[j]-alphas[i]) H = min(C, C+alphas[j]-alphas[i]) else: L = max(0, alphas[j]+alphas[i]-C) H = min(C, C+alphas[j]-alphas[i]) 这段代码在《机器学习实战》书中只说明了保证alpha在0与C之间，根据约束条件$0\leq\alpha_i\leq C\;i=1,2$，实际上是单变量的最优化问题。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo进行Latex公式渲染测试]]></title>
    <url>%2F2018%2F10%2F12%2FLatex%E6%B8%B2%E6%9F%93%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[安装插件首先需要安装Mathjax插件，MathJax是一款运行在浏览器中的开源的数学符号渲染引擎，使用MathJax可以方便的在浏览器中显示数学公式，不需要使用图片。目前，MathJax可以解析Latex、MathML和ASCIIMathML的标记语言。(Wiki) npm install hexo-math –save 更换渲染引擎接着要更换Hexo的markdown渲染引擎 npm uninstall hexo-renderer-marked –save npm install hexo-renderer-kramed –save 更改配置文件进入到主题目录，找到_config.yml文件，把mathjax默认的值改为true # MathJax Support mathjax: enable: true per_page: true #cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML cdn: //cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML 写博客在每次编写需要使用LaTeX渲染的博客文章中，需要在Front-matter里打开mathjax开关 title: test abbrlink: 7717490f date: 2018-10-12 10:06:12 tags: mathjax: true 测试 $T(n) = \Theta(n)$ $T(n) = \Theta(n)$]]></content>
      <categories>
        <category>技巧</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘 Week1作业]]></title>
    <url>%2F2018%2F09%2F19%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98WEEK1%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[第一周作业要求2组人工搜集中国科学院院士、中国工程院院士的名单，在百度自动获取院士个人主页url，编写爬虫采集院士人类学、学位、研究方向和国家科技奖数据，设计数据库表，保存数据。 小组分工CHY：科学院院士信息抓取ZBC：数据到MySQLme：工程院院士信息抓取 Step1 网站分析中国工程院院士名单：http://www.cae.cn/cae/html/main/col48/column_48_1.html 可以看到所有学部的院士信息已经汇总在一个网页中，后续编写爬虫抓取个人主页url很方便。 Step2 抓取url在编写爬虫时用到了XPath，XPath 是一门在 XML 文档中查找信息的语言。XPath 用于在 XML 文档中通过元素和属性进行导航。 XPath 使用路径表达式在 XML 文档中进行导航 XPath 包含一个标准函数库 XPath 是 XSLT 中的主要元素 XPath 是一个 W3C 标准在这里通过XPath的语法分别抓取li标签下的herf的内容和text的内容，以获得院士个人主页的url和院士的姓名，存储在list中。 def getURL(): #抓取工程院院士的URL和姓名 page = urllib.request.urlopen('http://www.cae.cn/cae/html/main/col48/column_48_1.html') html = page.read() urlList = [] sel = Selector(text=html, type="html") urlList = sel.xpath('//li[re:test(@class, "name_list")]//@href').extract() nameList = sel.xpath('//li[re:test(@class, "name_list")]//a/text()').extract() #print(url) i = 0 for i in range(len(urlList)): urlList[i] = "http://www.cae.cn" + urlList[i] return urlList, nameList #print(url) Step3 抓取个人信息接着仍使用XPath语法从urlList中依次爬取院士主页的个人信息。 infoPage = urllib.request.urlopen(academyURL) infoHTML = infoPage.read() infoSelect = Selector(text=infoHTML, type="html") info = infoSelect.xpath('//div[@class="intro"]/p/text()').extract()[0] return info Step4 信息提取可以发现院士信息页中大部分信息描述具有某些规律，比如描述院士在某个专业方面的成就时的描述会采用“金属材料及粉末冶金专家”、“耳鼻咽喉学专家”等以“专家”、“学家”结尾的格式，可以通过正则表达式和findall()函数找出对应的描述。 pattern = re.compile(r'(\d{4}年(?:\d{1,2}月)?(?:\d{0,2}日)?)(?:(?:出生)|(?:生，)|(?:生于)|(?:出生于))') birthday = pattern.findall(c) pattern2 = re.compile(r'^.*?(?:(?:学家)|(?:专家))') direction = pattern2.findall(c) pattern3 = re.compile(r'(?:获)[^(?:。)]+(?:奖)') award = pattern3.findall(c) pattern4 = re.compile(r'博士|硕士|学士') degree = pattern4.findall(c)]]></content>
      <categories>
        <category>作业</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据挖掘</tag>
        <tag>正则表达式</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用插件和IDM下载百度云盘]]></title>
    <url>%2F2018%2F09%2F10%2F%E4%BD%BF%E7%94%A8%E6%8F%92%E4%BB%B6%E5%92%8CIDM%E4%B8%8B%E8%BD%BD%E7%99%BE%E5%BA%A6%E4%BA%91%E7%9B%98%2F</url>
    <content type="text"><![CDATA[背景在某度云上保存了很多课程，但因为某度对于网盘速度的限制，只能寻找破解版某度云盘下载文件。听说破解版最近不好使了，在网上查找了很多方法，发现只有利用Chrome的插件和IDM才能达到最理想的下载效果。 软件 Chrome浏览器 IDM下载器（(Integrated Data Multiplexer） 扩展程序 BaiduPan Explorer 步骤 安装上述软件 使用插件抓取链接 使用IDM下载即可]]></content>
      <categories>
        <category>技巧</category>
      </categories>
      <tags>
        <tag>IDM</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好，Hexo]]></title>
    <url>%2F2018%2F09%2F09%2F%E4%BD%A0%E5%A5%BD%EF%BC%8CHexo%2F</url>
    <content type="text"></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F09%2F09%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
</search>
