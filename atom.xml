<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Fu&#39;s Lab</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://araid0628.github.io/"/>
  <updated>2019-04-08T13:15:01.230Z</updated>
  <id>https://araid0628.github.io/</id>
  
  <author>
    <name>Fu Hanlin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Introduction</title>
    <link href="https://araid0628.github.io/2019/04/03/Introduction/"/>
    <id>https://araid0628.github.io/2019/04/03/Introduction/</id>
    <published>2019-04-03T14:08:47.000Z</published>
    <updated>2019-04-08T13:15:01.230Z</updated>
    
    <content type="html"><![CDATA[<p><center>机器学习知识点总结</center><br>整理了一些机器学习的知识点，在公司用TexStudio写的，持续更新中。</p><p>如果pdf无法显示请打开Google Drive的分享链接<br><a href="https://drive.google.com/file/d/1_jf56rfrX1LpQks8DNC1e4gpfHIIpyly/view?usp=sharing" target="_blank" rel="noopener">https://drive.google.com/file/d/1_jf56rfrX1LpQks8DNC1e4gpfHIIpyly/view?usp=sharing</a></p><div class="row"><iframe src="https://drive.google.com/file/d/1_jf56rfrX1LpQks8DNC1e4gpfHIIpyly/preview" style="width:100%; height:550px"></iframe></div> ]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;center&gt;机器学习知识点总结&lt;/center&gt;&lt;br&gt;整理了一些机器学习的知识点，在公司用TexStudio写的，持续更新中。&lt;/p&gt;
&lt;p&gt;如果pdf无法显示请打开Google Drive的分享链接&lt;br&gt;&lt;a href=&quot;https://drive.google.
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://araid0628.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>项目实训-利用XGboost进行新楼盘价格预测</title>
    <link href="https://araid0628.github.io/2019/03/23/xgboost/"/>
    <id>https://araid0628.github.io/2019/03/23/xgboost/</id>
    <published>2019-03-23T10:41:24.000Z</published>
    <updated>2019-04-08T13:16:27.616Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本来这个需求不在列表中，受到Kaggle比赛：Kaggle Boston Housing(<a href="https://www.kaggle.com/c/boston-housing)的启发，加入了这个功能。因为数据全部靠自己收集，特征也远不如比赛中的数据集多，最终预测的效果我觉得虽然误差比较大，但是也有一定的参考价值。" target="_blank" rel="noopener">https://www.kaggle.com/c/boston-housing)的启发，加入了这个功能。因为数据全部靠自己收集，特征也远不如比赛中的数据集多，最终预测的效果我觉得虽然误差比较大，但是也有一定的参考价值。</a></p><h3 id="数据清洗和特征工程"><a href="#数据清洗和特征工程" class="headerlink" title="数据清洗和特征工程"></a>数据清洗和特征工程</h3><p>从数据库中抽取了一部分好量化的上海市数据作为基本信息，<br><img src="images/xgboost1.png" alt="Fig.1原始数据">在此基础之上，引入了该楼盘周边1km范围内地铁站数量、医院数量、学校数量、商场数量（数据来自百度API，可以参见另一篇blog）和该楼盘所在区域的区域均价。<br>从Figure1中可以看到从某壳网上爬取下来的数据中包含很多汉字、符号，还有缺失值需要填补，另外还有格式不统一的情况，所以在数据清洗上花了很多时间。对数据中的字符型数据转换：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据预处理，填充缺失值以及特征中含有字符的转换为数值型</span></span><br><span class="line"><span class="comment"># "price","propertyType","landscapingRatio","siteArea","floorAreaRatio","buildingArea","yearofpropertyRights",</span></span><br><span class="line"><span class="comment"># "numPlan","parkingRatio","propertycosts","parkingSpace","hospital","metro","school","mall","id"</span></span><br><span class="line"><span class="comment"># 住宅：1 写字楼：2 别墅：3 商业：4</span></span><br><span class="line">train.loc[train[<span class="string">"propertyType"</span>] == <span class="string">"住宅"</span>, <span class="string">"propertyType"</span>] = <span class="number">1</span></span><br><span class="line">train.loc[train[<span class="string">"propertyType"</span>] == <span class="string">"写字楼"</span>, <span class="string">"propertyType"</span>] = <span class="number">2</span></span><br><span class="line">train.loc[train[<span class="string">"propertyType"</span>] == <span class="string">"别墅"</span>, <span class="string">"propertyType"</span>] = <span class="number">3</span></span><br><span class="line">train.loc[train[<span class="string">"propertyType"</span>] == <span class="string">"商业"</span>, <span class="string">"propertyType"</span>] = <span class="number">4</span></span><br></pre></td></tr></table></figure></p><p>对部分特征统一数据格式后，缺失值用均值进行填补：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">'landscapingRatio'</span>] = train[<span class="string">'landscapingRatio'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'landscapingRatio'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train[<span class="string">'siteArea'</span>] = train[<span class="string">'siteArea'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'siteArea'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train[<span class="string">'floorAreaRatio'</span>] = train[<span class="string">'floorAreaRatio'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'floorAreaRatio'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train[<span class="string">'buildingArea'</span>] = train[<span class="string">'buildingArea'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'buildingArea'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train = train.fillna(<span class="number">0</span>)</span><br><span class="line">train[<span class="string">'yearofpropertyRights'</span>] = train[<span class="string">'yearofpropertyRights'</span>].astype(float)</span><br><span class="line">train[<span class="string">'numPlan'</span>] = train[<span class="string">'numPlan'</span>].astype(int)</span><br><span class="line">train[<span class="string">'parkingRatio'</span>] = train[<span class="string">'parkingRatio'</span>].astype(float)</span><br><span class="line">train[<span class="string">'propertycosts'</span>] = train[<span class="string">'propertycosts'</span>].astype(float)</span><br><span class="line">train[<span class="string">'parkingSpace'</span>] = train[<span class="string">'parkingSpace'</span>].astype(int)</span><br><span class="line">train[<span class="string">'yearofpropertyRights'</span>] = train[<span class="string">'yearofpropertyRights'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'yearofpropertyRights'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train[<span class="string">'numPlan'</span>] = train[<span class="string">'numPlan'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'numPlan'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train[<span class="string">'parkingRatio'</span>] = train[<span class="string">'parkingRatio'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'parkingRatio'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train[<span class="string">'propertycosts'</span>] = train[<span class="string">'propertycosts'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'propertycosts'</span>].transform(<span class="string">'mean'</span>))</span><br><span class="line">train[<span class="string">'parkingSpace'</span>] = train[<span class="string">'parkingSpace'</span>].fillna(train.groupby(<span class="string">'propertyType'</span>)[<span class="string">'parkingSpace'</span>].transform(<span class="string">'mean'</span>))</span><br></pre></td></tr></table></figure></p><p><img src="images/xgboost2.png" alt="Fig.1清洗完成"></p><h3 id="XGboost简介"><a href="#XGboost简介" class="headerlink" title="XGboost简介"></a>XGboost简介</h3><p>后期会把在公司做的seminar的ppt放上来</p><h3 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h3><p>Step 1<br>读取数据集，为了增强模型的泛化能力，筛掉了单价超过50000元/平方米的数据，实验结果证明效果对二三线城市的预测效果比较好，但在像上海、北京这样房价过高的城市表现一般。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dataset_train = <span class="string">'house_trainset2.csv'</span></span><br><span class="line">data_train = pd.read_csv(dataset_train)</span><br><span class="line">data_train = data_train[data_train[<span class="string">'price'</span>] &lt;= <span class="number">49999</span>]</span><br><span class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">pd.set_option(<span class="string">'display.width'</span>, <span class="keyword">None</span>)</span><br><span class="line">X = data_train.drop([<span class="string">'id'</span>, <span class="string">'price'</span>, <span class="string">'Unnamed: 0'</span>, <span class="string">'numPlan'</span>], axis=<span class="number">1</span>)</span><br><span class="line">X = scaler.fit_transform(X)</span><br><span class="line">y = data_train.price</span><br></pre></td></tr></table></figure></p><p>随机拆分训练集和测试集后，fit到模型中，模型的参数调整用了Sklearn中的GridSearchCV,它存在的意义就是自动调参，只要把参数输进去，就能给出最优化的结果和参数。但是这个方法适合于小数据集，一旦数据的量级上去了，很难得出结果。数据量比较大的时候可以使用一个快速调优的方法——坐标下降。它其实是一种贪心算法：拿当前对模型影响最大的参数调优，直到最优化；再拿下一个影响最大的参数调优，如此下去，直到所有的参数调整完毕。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">123</span>)</span><br><span class="line">cv_params = &#123;<span class="string">'n_estimators'</span>: [<span class="number">400</span>, <span class="number">500</span>, <span class="number">600</span>, <span class="number">700</span>, <span class="number">800</span>]&#125;</span><br><span class="line">other_params = &#123;<span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'n_estimators'</span>: <span class="number">400</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>, <span class="string">'min_child_weight'</span>: <span class="number">1</span>, <span class="string">'seed'</span>: <span class="number">0</span>, <span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'colsample_bytree'</span>: <span class="number">0.8</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'reg_alpha'</span>: <span class="number">0</span>, <span class="string">'reg_lambda'</span>: <span class="number">1</span>&#125;</span><br><span class="line">optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring=<span class="string">'r2'</span>, cv=<span class="number">5</span>, verbose=<span class="number">1</span>, n_jobs=<span class="number">5</span>)</span><br><span class="line">optimized_GBM.fit(X_train, y_train)</span><br><span class="line">evalute_result = optimized_GBM.grid_scores_</span><br><span class="line">print(<span class="string">'每轮迭代运行结果:&#123;0&#125;'</span>.format(evalute_result))</span><br><span class="line">print(<span class="string">'参数的最佳取值：&#123;0&#125;'</span>.format(optimized_GBM.best_params_))</span><br><span class="line">print(<span class="string">'最佳模型得分:&#123;0&#125;'</span>.format(optimized_GBM.best_score_))</span><br><span class="line">print(xg_reg.feature_importances_)</span><br></pre></td></tr></table></figure></p><h3 id="预测结果"><a href="#预测结果" class="headerlink" title="预测结果"></a>预测结果</h3><p><img src="images/xgb.png" alt="结果1"><br><img src="images/web.png" alt="结果2"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;本来这个需求不在列表中，受到Kaggle比赛：Kaggle Boston Housing(&lt;a href=&quot;https://www.kagg
      
    
    </summary>
    
    
      <category term="机器学习" scheme="https://araid0628.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://araid0628.github.io/tags/Python/"/>
    
      <category term="项目实训" scheme="https://araid0628.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%AE%AD/"/>
    
      <category term="XGboost" scheme="https://araid0628.github.io/tags/XGboost/"/>
    
  </entry>
  
  <entry>
    <title>项目实训-第二周总结</title>
    <link href="https://araid0628.github.io/2019/03/11/week2/"/>
    <id>https://araid0628.github.io/2019/03/11/week2/</id>
    <published>2019-03-11T13:40:06.000Z</published>
    <updated>2019-03-23T11:02:01.433Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>第二周结束项目的大部分简单需求已经实现，超过了预期的速度。两个组员在隔壁新国大实习，我周五也要去Bosch实习了，下周要加快进度。</p><h3 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h3><p>网站的定位是面向购买新房的投资者或者有住房提升需求的买房者的功能性网站，数据分析＞房源展示。</p><h3 id="已完成的需求"><a href="#已完成的需求" class="headerlink" title="已完成的需求"></a>已完成的需求</h3><ol><li>按用户输入城市名称，爬取和显示城市不同小区，不同区域的房价，并用柱状图显示<br><img src="images/week2_1.png" alt="Fig.1显示">看了周一的模拟产品发布以后，发现隔壁组的UI做的很好看，扁平化设计，准备在产品功能实现后再调整。</li><li>按年份，月份，显示和分析某区域房价走向和趋势<br><img src="images/week2_2.png" alt="Fig.2图表1">收集到的数据的粒度到月，住建局有到天的成交数据，但是很多特征都没有就没有采集。<br><img src="images/week2_3.png" alt="Fig.3图表2">ECharts确实很好用，提供了一些直观、易用的交互方式以方便对所展现数据的再加工。<h3 id="待完成的需求"><a href="#待完成的需求" class="headerlink" title="待完成的需求"></a>待完成的需求</h3>预测模型的训练已经完成，为了不和其他组撞车，准备加入两个预测模块。<br>1.新楼盘开盘价预测（博文会在第三周整理后发布）<br>输入：用户输入新楼盘的一些信息，城市+小区名称（在后台调用百度地图API返回小区周边信息数据）、绿化率、容积率、车位比等数据<br>输出：该新楼盘的开盘价格<br><img src="images/Figure_2.png" alt="Fig.4预测1">(基于XgBoost)图中的蓝色点是训练集中上海新楼盘的真实信息，但是训练的结果和Kaggle中波士顿房价预测那题的结果相差甚远，我想有几个原因：第一是上海主城区房价过高，但是新楼盘少，新城区房价较低，新楼盘多，这些离群点让模型产生了较大误差；第二，Kaggle比赛的数据集很全，虽然说有缺失值和部分错误值，但是用Pandas完全可以解决这些小错误，我们这次预测的数据集60%来自链家，40%是自己收集的，在专业性上相差较多，导致没有比赛数据集所呈现的统计规律。<br>2.房价走势预测（博文会在第三周整理后发布）<br>输入：数据库中某城市粒度位月的历史房价<br>输出：未来一个月的房价趋势<br><img src="images/Figure_1.png" alt="Fig.5预测2">（基于LSTM）</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;第二周结束项目的大部分简单需求已经实现，超过了预期的速度。两个组员在隔壁新国大实习，我周五也要去Bosch实习了，下周要加快进度。&lt;/p&gt;

      
    
    </summary>
    
      <category term="项目实训" scheme="https://araid0628.github.io/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%AE%AD/"/>
    
    
      <category term="项目实训" scheme="https://araid0628.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%AE%AD/"/>
    
  </entry>
  
  <entry>
    <title>Pandas处理数据时replace方法失效</title>
    <link href="https://araid0628.github.io/2019/03/05/week123/"/>
    <id>https://araid0628.github.io/2019/03/05/week123/</id>
    <published>2019-03-05T13:04:48.000Z</published>
    <updated>2019-03-05T13:24:28.002Z</updated>
    
    <content type="html"><![CDATA[<h3 id="BUG复现"><a href="#BUG复现" class="headerlink" title="BUG复现"></a>BUG复现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.replace(<span class="string">'%'</span>, <span class="string">''</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>使用replace函数的目的是：在清洗房价数据时替换掉不需要的单位，如“%”，“元/m²/月”等。但在使用函数时发现无法生效，查了网上相关信息后试了多种方法也无法解决这个问题，如先取列之后再进行replace。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">"landscapingRatio"</span>].replace(<span class="string">'%'</span>, <span class="string">''</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p><h3 id="原因推测"><a href="#原因推测" class="headerlink" title="原因推测"></a>原因推测</h3><p>dataframe中每个列中值的dtypes不同，导致无法replace。</p><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>使用map()和lambda函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">"landscapingRatio"</span>] = train[<span class="string">"landscapingRatio"</span>].map(<span class="keyword">lambda</span> x: x.replace(<span class="string">'%'</span>, <span class="string">''</span>))</span><br></pre></td></tr></table></figure></p><p>map() 会根据提供的函数对指定序列做映射。<br>第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;BUG复现&quot;&gt;&lt;a href=&quot;#BUG复现&quot; class=&quot;headerlink&quot; title=&quot;BUG复现&quot;&gt;&lt;/a&gt;BUG复现&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter
      
    
    </summary>
    
      <category term="项目实训" scheme="https://araid0628.github.io/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%AE%AD/"/>
    
    
      <category term="Python" scheme="https://araid0628.github.io/tags/Python/"/>
    
      <category term="房价预测" scheme="https://araid0628.github.io/tags/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/"/>
    
      <category term="Pandas" scheme="https://araid0628.github.io/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>项目实训第一周总结</title>
    <link href="https://araid0628.github.io/2019/03/03/housepricingweek1/"/>
    <id>https://araid0628.github.io/2019/03/03/housepricingweek1/</id>
    <published>2019-03-03T13:22:38.000Z</published>
    <updated>2019-03-12T14:29:37.644Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>寒假前已经定好了这次项目实训的题目，放假的时候群里关于房价数据爬虫的讨论随着一句“过完年再说”戛然而止，然而第一周已经结束了才空出时间来写总结。</p><h3 id="项目需求"><a href="#项目需求" class="headerlink" title="项目需求"></a>项目需求</h3><p>城市房价分析系统<br>技术类别：<br>Web，网络爬虫，数据分析<br>基本功能：<br>通过爬取链家网，我爱我家等中介机构，以及城市建设局网站数据，实现对指定城市的房价进行排序和分析，并结合一定规律进行预测<br>难易程度：中等<br>需求实现：</p><ol><li>按用户输入城市名称，爬取和显示城市不同小区，不同区域的房价，并用柱状图显示</li><li>按年份，月份，显示和分析某区域房价走向和趋势</li><li>对比相同价格下不同城市的房产品牌</li><li>对比不同城市房价走向，并进行归类分析</li><li>实现房价波动的简单预测</li></ol><h3 id="需求理解"><a href="#需求理解" class="headerlink" title="需求理解"></a>需求理解</h3><p>1.项目是什么？<br>一个Web，可以向用户展示粒度从市—行政区—具体楼盘的统计数据，可以根据用户提供的新楼盘数据做预测。<br>2.项目怎么做？<br>Java Web(Spring bot, vue.js, Echarts)<br>Python(bs4, sklearn, pandas等)<br>MySQL<br>百度API（POI相关信息获取）<br>预测模型XgBoost + LR/DT, 是否采用Deep Learning视项目进度决定</p><h3 id="开发模式"><a href="#开发模式" class="headerlink" title="开发模式"></a>开发模式</h3><p>Scrum敏捷开发模式，lm担任产品经理，ltz担任技术主管，我是master。作为master在项目中要负责管理上的事务很多，经理日报，进度控制，每日组会，团建等等，对人际沟通能力是个很好的提升。组员都很自觉，分工我和lm负责数据和预测部分，另外三位负责Web。</p><h3 id="第一周进度"><a href="#第一周进度" class="headerlink" title="第一周进度"></a>第一周进度</h3><ol><li>数据部分：爬虫完成，爬取了某壳网上一线城市和二线城市的数据</li><li>Web部分：通过百度地图的控件可以在地图上显示城市和行政区的统计数据，校对经纬度花了挺久。</li><li>预测部分：数据清洗中，第二周预测模块应该能实现。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;寒假前已经定好了这次项目实训的题目，放假的时候群里关于房价数据爬虫的讨论随着一句“过完年再说”戛然而止，然而第一周已经结束了才空出时间来写总
      
    
    </summary>
    
      <category term="项目实训" scheme="https://araid0628.github.io/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%AE%AD/"/>
    
    
      <category term="房价预测" scheme="https://araid0628.github.io/tags/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>百度地图API解析</title>
    <link href="https://araid0628.github.io/2019/02/28/baiduAPI/"/>
    <id>https://araid0628.github.io/2019/02/28/baiduAPI/</id>
    <published>2019-02-28T13:46:30.000Z</published>
    <updated>2019-03-23T11:59:52.504Z</updated>
    
    <content type="html"><![CDATA[<h3 id="功能简介"><a href="#功能简介" class="headerlink" title="功能简介"></a>功能简介</h3><p>百度地图Web服务API为开发者提供http/https接口，即开发者通过http/https形式发起检索请求，获取返回json或xml格式的检索数据。用户可以基于此开发JavaScript、C#、C++、Java等语言的地图应用。<br><a href="http://lbsyun.baidu.com/index.php?title=webapi" target="_blank" rel="noopener">http://lbsyun.baidu.com/index.php?title=webapi</a><br>文档非常全面，可以获得很多信息，包括经纬度，经纬度周边任意距离任意类型场所信息，如医院、地铁站等，为预测做准备。<br>以正/逆地理编码服务为例。</p><h3 id="Python如何解析API返回的json"><a href="#Python如何解析API返回的json" class="headerlink" title="Python如何解析API返回的json"></a>Python如何解析API返回的json</h3><p>所用到的库<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen, quote</span><br></pre></td></tr></table></figure></p><h3 id="获得API传回的json信息"><a href="#获得API传回的json信息" class="headerlink" title="获得API传回的json信息"></a>获得API传回的json信息</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showLocation&amp;&amp;showLocation(&#123;"status":0,"result":&#123;"location":&#123;"lng":120.75204667293927,"lat":31.27628928466111&#125;,"precise":1,"confidence":80,"comprehension":100,"level":"道路"&#125;&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getlnglat</span><span class="params">(address)</span>:</span></span><br><span class="line">    url = <span class="string">'http://api.map.baidu.com/geocoder/v2/'</span></span><br><span class="line">    output = <span class="string">'json'</span></span><br><span class="line">    ak = <span class="string">'你的密钥'</span></span><br><span class="line">    add = quote(address) <span class="comment"># 由于本文城市变量为中文，为防止乱码，先用quote进行编码</span></span><br><span class="line">    uri = url + <span class="string">'?'</span> + <span class="string">'address='</span> + add  + <span class="string">'&amp;output='</span> + output + <span class="string">'&amp;ak='</span> + ak</span><br><span class="line">    print(uri)</span><br><span class="line">    req = urlopen(uri)</span><br><span class="line">    res = req.read().decode() <span class="comment"># 将其他编码的字符串解码成unicode</span></span><br><span class="line">    responseInfo = json.loads(res) <span class="comment"># 对json数据进行解析</span></span><br><span class="line">    <span class="keyword">return</span> responseInfo</span><br></pre></td></tr></table></figure><h3 id="取得所需的信息"><a href="#取得所需的信息" class="headerlink" title="取得所需的信息"></a>取得所需的信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">add = <span class="string">"江苏省苏州市苏州工业园区林泉街399号东南大学软件学院"</span>  <span class="comment"># 你所要查询的地址</span></span><br><span class="line">lat = getlnglat(add)[<span class="string">'result'</span>][<span class="string">'location'</span>][<span class="string">'lat'</span>]  <span class="comment"># 获得纬度</span></span><br><span class="line">lng = getlnglat(add)[<span class="string">'result'</span>][<span class="string">'location'</span>][<span class="string">'lng'</span>]  <span class="comment"># 获得经度</span></span><br></pre></td></tr></table></figure><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>lat = 31.27628928466111<br>lng = 120.75204667293927</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;功能简介&quot;&gt;&lt;a href=&quot;#功能简介&quot; class=&quot;headerlink&quot; title=&quot;功能简介&quot;&gt;&lt;/a&gt;功能简介&lt;/h3&gt;&lt;p&gt;百度地图Web服务API为开发者提供http/https接口，即开发者通过http/https形式发起检索请求，获取返回js
      
    
    </summary>
    
      <category term="项目实训" scheme="https://araid0628.github.io/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%AE%AD/"/>
    
    
      <category term="百度" scheme="https://araid0628.github.io/tags/%E7%99%BE%E5%BA%A6/"/>
    
      <category term="API" scheme="https://araid0628.github.io/tags/API/"/>
    
      <category term="json" scheme="https://araid0628.github.io/tags/json/"/>
    
      <category term="Python" scheme="https://araid0628.github.io/tags/Python/"/>
    
      <category term="房价预测" scheme="https://araid0628.github.io/tags/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯估计与最大似然估计</title>
    <link href="https://araid0628.github.io/2018/12/02/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1%E4%B8%8E%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://araid0628.github.io/2018/12/02/贝叶斯估计与极大似然估计的区别/</id>
    <published>2018-12-02T07:50:19.000Z</published>
    <updated>2018-12-02T08:29:55.139Z</updated>
    
    <content type="html"><![CDATA[<p>贝叶斯估计：估计参数$\theta$是随机变量，根据观测数据对参数的分布进行估计，考虑先验分布。</p><p>最大似然估计：参数$\theta$是未知的，根据真实数据通过最大化似然函数$\mathop{\arg\max}_{\theta}L(\theta|D)$来估计$\theta$的值</p><div class="table-container"><table><thead><tr><th></th><th>最大似然估计</th><th>贝叶斯估计</th></tr></thead><tbody><tr><td>计算复杂度</td><td>微分</td><td>多重积分</td></tr><tr><td>先验信息的信任程度</td><td>不准确</td><td>准确</td></tr><tr><td>例如$p(x丨\theta)$</td><td>与初始假设一致</td><td>与初始假设不一致</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;贝叶斯估计：估计参数$\theta$是随机变量，根据观测数据对参数的分布进行估计，考虑先验分布。&lt;/p&gt;
&lt;p&gt;最大似然估计：参数$\theta$是未知的，根据真实数据通过最大化似然函数$\mathop{\arg\max}_{\theta}L(\theta|D)$来估计$\
      
    
    </summary>
    
      <category term="机器学习" scheme="https://araid0628.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="贝叶斯" scheme="https://araid0628.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
      <category term="最大似然估计" scheme="https://araid0628.github.io/tags/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>算法导论4.5-主方法</title>
    <link href="https://araid0628.github.io/2018/11/12/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA4-5-%E4%B8%BB%E6%96%B9%E6%B3%95/"/>
    <id>https://araid0628.github.io/2018/11/12/算法导论4-5-主方法/</id>
    <published>2018-11-12T14:25:12.000Z</published>
    <updated>2018-11-12T14:33:54.301Z</updated>
    
    <content type="html"><![CDATA[<p>算法导论练习4.5-1<br>对下列递归式，使用主方法求出渐进紧缺界:</p><h4 id="T-n-2T-n-4-1"><a href="#T-n-2T-n-4-1" class="headerlink" title="$T(n) = 2T(n/4) + 1$"></a>$T(n) = 2T(n/4) + 1$</h4><h4 id="T-n-2T-n-4-sqrt-n"><a href="#T-n-2T-n-4-sqrt-n" class="headerlink" title="$T(n) = 2T(n/4) + \sqrt{n}$"></a>$T(n) = 2T(n/4) + \sqrt{n}$</h4><h4 id="T-n-2T-n-4-n"><a href="#T-n-2T-n-4-n" class="headerlink" title="$T(n) = 2T(n/4) + n$"></a>$T(n) = 2T(n/4) + n$</h4><h4 id="T-n-2T-n-4-n-2"><a href="#T-n-2T-n-4-n-2" class="headerlink" title="$T(n) = 2T(n/4) + n^2$"></a>$T(n) = 2T(n/4) + n^2$</h4><p>Answer：</p><h4 id="Theta-n-log-4-2-Theta-sqrt-n"><a href="#Theta-n-log-4-2-Theta-sqrt-n" class="headerlink" title="$\Theta(n^{\log_4{2}}) = \Theta(\sqrt{n})$"></a>$\Theta(n^{\log_4{2}}) = \Theta(\sqrt{n})$</h4><h4 id="Theta-n-log-4-2-lg-n-Theta-sqrt-n-lg-n"><a href="#Theta-n-log-4-2-lg-n-Theta-sqrt-n-lg-n" class="headerlink" title="$\Theta(n^{\log_4{2}}\lg{n}) = \Theta(\sqrt{n}\lg{n})$"></a>$\Theta(n^{\log_4{2}}\lg{n}) = \Theta(\sqrt{n}\lg{n})$</h4><h4 id="Theta-n"><a href="#Theta-n" class="headerlink" title="$\Theta(n)$"></a>$\Theta(n)$</h4><h4 id="Theta-n-2"><a href="#Theta-n-2" class="headerlink" title="$\Theta(n^2)$"></a>$\Theta(n^2)$</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;算法导论练习4.5-1&lt;br&gt;对下列递归式，使用主方法求出渐进紧缺界:&lt;/p&gt;
&lt;h4 id=&quot;T-n-2T-n-4-1&quot;&gt;&lt;a href=&quot;#T-n-2T-n-4-1&quot; class=&quot;headerlink&quot; title=&quot;$T(n) = 2T(n/4) + 1$&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="笔记" scheme="https://araid0628.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="算法导论" scheme="https://araid0628.github.io/tags/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/"/>
    
      <category term="递归" scheme="https://araid0628.github.io/tags/%E9%80%92%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习实战》SVM补充内容</title>
    <link href="https://araid0628.github.io/2018/10/21/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E3%80%8BSVM%E8%A1%A5%E5%85%85%E5%86%85%E5%AE%B9/"/>
    <id>https://araid0628.github.io/2018/10/21/《机器学习实战》SVM补充内容/</id>
    <published>2018-10-21T12:28:49.000Z</published>
    <updated>2018-10-21T13:07:58.260Z</updated>
    
    <content type="html"><![CDATA[<p>对于《机器学习实战》一书SVM章节程序清单6-2 简化版SVM算法中部分代码的数学原理补充</p><p><pre><code>    if(labelMat[i] != labelMat[j]):        L = max(0, alphas[j]-alphas[i])        H = min(C, C+alphas[j]-alphas[i])    else:        L = max(0, alphas[j]+alphas[i]-C)        H = min(C, C+alphas[j]-alphas[i])</code></pre><br>这段代码在《机器学习实战》书中只说明了保证alpha在0与C之间，根据约束条件$0\leq\alpha_i\leq C\;i=1,2$，实际上是单变量的最优化问题。<br><img src="images/SVM1_p1.png" alt="李航《统计学习实战》P130"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于《机器学习实战》一书SVM章节程序清单6-2 简化版SVM算法中部分代码的数学原理补充&lt;/p&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;
    if(labelMat[i] != labelMat[j]):
        L = max(0, alphas[j]-alphas[
      
    
    </summary>
    
      <category term="机器学习" scheme="https://araid0628.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://araid0628.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="SVM" scheme="https://araid0628.github.io/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>使用Hexo进行Latex公式渲染测试</title>
    <link href="https://araid0628.github.io/2018/10/12/Latex%E6%B8%B2%E6%9F%93%E6%B5%8B%E8%AF%95/"/>
    <id>https://araid0628.github.io/2018/10/12/Latex渲染测试/</id>
    <published>2018-10-12T02:06:12.000Z</published>
    <updated>2018-10-21T12:45:57.461Z</updated>
    
    <content type="html"><![CDATA[<h3 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h3><p>首先需要安装Mathjax插件，MathJax是一款运行在浏览器中的开源的数学符号渲染引擎，使用MathJax可以方便的在浏览器中显示数学公式，不需要使用图片。目前，MathJax可以解析Latex、MathML和ASCIIMathML的标记语言。(Wiki)</p><pre><code> npm install hexo-math –save</code></pre><h3 id="更换渲染引擎"><a href="#更换渲染引擎" class="headerlink" title="更换渲染引擎"></a>更换渲染引擎</h3><p>接着要更换Hexo的markdown渲染引擎</p><pre><code> npm uninstall hexo-renderer-marked –save npm install hexo-renderer-kramed –save</code></pre><h3 id="更改配置文件"><a href="#更改配置文件" class="headerlink" title="更改配置文件"></a>更改配置文件</h3><p>进入到主题目录，找到_config.yml文件，把mathjax默认的值改为true</p><pre><code> # MathJax Supportmathjax:  enable: true  per_page: true  #cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML  cdn: //cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML</code></pre><h3 id="写博客"><a href="#写博客" class="headerlink" title="写博客"></a>写博客</h3><p>在每次编写需要使用LaTeX渲染的博客文章中，需要在Front-matter里打开mathjax开关</p><pre><code> title: testabbrlink: 7717490fdate: 2018-10-12 10:06:12tags:mathjax: true</code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p><pre><code> $T(n) = \Theta(n)$</code></pre><br>$T(n) = \Theta(n)$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;安装插件&quot;&gt;&lt;a href=&quot;#安装插件&quot; class=&quot;headerlink&quot; title=&quot;安装插件&quot;&gt;&lt;/a&gt;安装插件&lt;/h3&gt;&lt;p&gt;首先需要安装Mathjax插件，MathJax是一款运行在浏览器中的开源的数学符号渲染引擎，使用MathJax可以方便的在浏
      
    
    </summary>
    
      <category term="技巧" scheme="https://araid0628.github.io/categories/%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="Hexo" scheme="https://araid0628.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘 Week1作业</title>
    <link href="https://araid0628.github.io/2018/09/19/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98WEEK1%E4%BD%9C%E4%B8%9A/"/>
    <id>https://araid0628.github.io/2018/09/19/数据挖掘WEEK1作业/</id>
    <published>2018-09-19T12:46:29.000Z</published>
    <updated>2018-10-11T09:29:01.411Z</updated>
    
    <content type="html"><![CDATA[<h3 id="第一周作业要求"><a href="#第一周作业要求" class="headerlink" title="第一周作业要求"></a>第一周作业要求</h3><p>2组<br>人工搜集中国科学院院士、中国工程院院士的名单，在百度自动获取院士个人主页url，编写爬虫采集院士人类学、学位、研究方向和国家科技奖数据，设计数据库表，保存数据。</p><h3 id="小组分工"><a href="#小组分工" class="headerlink" title="小组分工"></a>小组分工</h3><p>CHY：科学院院士信息抓取<br>ZBC：数据到MySQL<br>me：工程院院士信息抓取</p><h3 id="Step1-网站分析"><a href="#Step1-网站分析" class="headerlink" title="Step1 网站分析"></a>Step1 网站分析</h3><p>中国工程院院士名单：<a href="http://www.cae.cn/cae/html/main/col48/column_48_1.html" target="_blank" rel="noopener">http://www.cae.cn/cae/html/main/col48/column_48_1.html</a> 可以看到所有学部的院士信息已经汇总在一个网页中，后续编写爬虫抓取个人主页url很方便。<br><img src="images/week1_p1.png" alt="view-sourse"></p><h3 id="Step2-抓取url"><a href="#Step2-抓取url" class="headerlink" title="Step2 抓取url"></a>Step2 抓取url</h3><p>在编写爬虫时用到了XPath，XPath 是一门在 XML 文档中查找信息的语言。XPath 用于在 XML 文档中通过元素和属性进行导航。</p><ul><li>XPath 使用路径表达式在 XML 文档中进行导航</li><li>XPath 包含一个标准函数库</li><li>XPath 是 XSLT 中的主要元素</li><li>XPath 是一个 W3C 标准<br>在这里通过XPath的语法分别抓取li标签下的herf的内容和text的内容，以获得院士个人主页的url和院士的姓名，存储在list中。<pre><code> def getURL():                #抓取工程院院士的URL和姓名  page = urllib.request.urlopen('http://www.cae.cn/cae/html/main/col48/column_48_1.html')  html = page.read()  urlList = []  sel = Selector(text=html, type="html")  urlList = sel.xpath('//li[re:test(@class, "name_list")]//@href').extract()  nameList = sel.xpath('//li[re:test(@class, "name_list")]//a/text()').extract()  #print(url)  i = 0  for i in range(len(urlList)):      urlList[i] = "http://www.cae.cn" + urlList[i]  return urlList, nameList  #print(url)</code></pre></li></ul><h3 id="Step3-抓取个人信息"><a href="#Step3-抓取个人信息" class="headerlink" title="Step3 抓取个人信息"></a>Step3 抓取个人信息</h3><p>接着仍使用XPath语法从urlList中依次爬取院士主页的个人信息。<br><img src="images/week1_p2.png" alt="view-sourse2"></p><pre><code>    infoPage = urllib.request.urlopen(academyURL)    infoHTML = infoPage.read()    infoSelect = Selector(text=infoHTML, type="html")    info = infoSelect.xpath('//div[@class="intro"]/p/text()').extract()[0]    return info</code></pre><h3 id="Step4-信息提取"><a href="#Step4-信息提取" class="headerlink" title="Step4 信息提取"></a>Step4 信息提取</h3><p>可以发现院士信息页中大部分信息描述具有某些规律，比如描述院士在某个专业方面的成就时的描述会采用“金属材料及粉末冶金专家”、“耳鼻咽喉学专家”等以“专家”、“学家”结尾的格式，可以通过正则表达式和findall()函数找出对应的描述。</p><pre><code>    pattern = re.compile(r'(\d{4}年(?:\d{1,2}月)?(?:\d{0,2}日)?)(?:(?:出生)|(?:生，)|(?:生于)|(?:出生于))')    birthday = pattern.findall(c)    pattern2 = re.compile(r'^.*?(?:(?:学家)|(?:专家))')    direction = pattern2.findall(c)    pattern3 = re.compile(r'(?:获)[^(?:。)]+(?:奖)')    award = pattern3.findall(c)    pattern4 = re.compile(r'博士|硕士|学士')    degree = pattern4.findall(c)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;第一周作业要求&quot;&gt;&lt;a href=&quot;#第一周作业要求&quot; class=&quot;headerlink&quot; title=&quot;第一周作业要求&quot;&gt;&lt;/a&gt;第一周作业要求&lt;/h3&gt;&lt;p&gt;2组&lt;br&gt;人工搜集中国科学院院士、中国工程院院士的名单，在百度自动获取院士个人主页url，编写爬虫
      
    
    </summary>
    
      <category term="作业" scheme="https://araid0628.github.io/categories/%E4%BD%9C%E4%B8%9A/"/>
    
    
      <category term="Python" scheme="https://araid0628.github.io/tags/Python/"/>
    
      <category term="数据挖掘" scheme="https://araid0628.github.io/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="正则表达式" scheme="https://araid0628.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
      <category term="爬虫" scheme="https://araid0628.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>使用插件和IDM下载百度云盘</title>
    <link href="https://araid0628.github.io/2018/09/10/%E4%BD%BF%E7%94%A8%E6%8F%92%E4%BB%B6%E5%92%8CIDM%E4%B8%8B%E8%BD%BD%E7%99%BE%E5%BA%A6%E4%BA%91%E7%9B%98/"/>
    <id>https://araid0628.github.io/2018/09/10/使用插件和IDM下载百度云盘/</id>
    <published>2018-09-10T04:58:54.000Z</published>
    <updated>2018-09-19T12:53:52.835Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在某度云上保存了很多课程，但因为某度对于网盘速度的限制，只能寻找破解版某度云盘下载文件。听说破解版最近不好使了，在网上查找了很多方法，发现只有利用Chrome的插件和IDM才能达到最理想的下载效果。</p><h3 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h3><ul><li>Chrome浏览器</li><li>IDM下载器（(Integrated Data Multiplexer）</li><li>扩展程序 BaiduPan Explorer</li></ul><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ul><li>安装上述软件</li><li>使用插件抓取链接<br><img src="images/idm1.png" alt="链接"></li><li>使用IDM下载即可</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;在某度云上保存了很多课程，但因为某度对于网盘速度的限制，只能寻找破解版某度云盘下载文件。听说破解版最近不好使了，在网上查找了很多方法，发现只
      
    
    </summary>
    
      <category term="技巧" scheme="https://araid0628.github.io/categories/%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="IDM" scheme="https://araid0628.github.io/tags/IDM/"/>
    
      <category term="插件" scheme="https://araid0628.github.io/tags/%E6%8F%92%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>你好，Hexo</title>
    <link href="https://araid0628.github.io/2018/09/09/%E4%BD%A0%E5%A5%BD%EF%BC%8CHexo/"/>
    <id>https://araid0628.github.io/2018/09/09/你好，Hexo/</id>
    <published>2018-09-09T02:25:49.000Z</published>
    <updated>2018-09-09T07:07:47.559Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="杂谈" scheme="https://araid0628.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="杂谈" scheme="https://araid0628.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://araid0628.github.io/2018/09/09/hello-world/"/>
    <id>https://araid0628.github.io/2018/09/09/hello-world/</id>
    <published>2018-09-09T01:59:13.337Z</published>
    <updated>2018-09-09T07:08:59.045Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="杂谈" scheme="https://araid0628.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="杂谈" scheme="https://araid0628.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
</feed>
